{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbdd82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate bns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16c9347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm, norm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from BNS_JT import cpm, variable\n",
    "from BNS_JT.trans import get_arcs_length, get_all_paths_and_times, get_path_time_idx\n",
    "from BNS_JT.cpm import variable_elim, mcs_product, single_sample, get_sample_order\n",
    "from BNS_JT.branch import get_cmat_from_branches, branch_and_bound\n",
    "from BNS_JT import bnb_fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58ac5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "HOME = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4dde8c",
   "metadata": {},
   "source": [
    "# Network\n",
    "\n",
    "This is a hypothetical network with arbitrary scales, epicentre location and road types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fece4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e1': 20.09975124224178, 'e2': 18.741664813991314, 'e3': 20.0, 'e4': 18.527007313648905, 'e5': 18.527007313648905, 'e6': 17.11724276862369, 'e7': 17.0}\n",
      "{('n1', 'n4'): [(['e1', 'e3', 'e5', 'e7', 'e6'], 0.2733333333333333), (['e1', 'e4', 'e6'], 0.16666666666666669), (['e2'], 0.06)], ('n1', 'n5'): [(['e1', 'e3', 'e5', 'e7'], 0.20666666666666667), (['e1', 'e4'], 0.1), (['e2', 'e6'], 0.12666666666666665)], ('n1', 'n6'): [(['e1', 'e3', 'e5'], 0.16666666666666666), (['e1', 'e4', 'e7'], 0.14), (['e2', 'e6', 'e4', 'e3', 'e5'], 0.3133333333333333), (['e2', 'e6', 'e7'], 0.16666666666666666)]}\n"
     ]
    }
   ],
   "source": [
    "node_coords = {'n1': (0, 0),\n",
    "               'n2': (0, -2),\n",
    "               'n3': (0, -4),\n",
    "               'n4': (3, 0),\n",
    "               'n5': (3, -2),\n",
    "               'n6': (3, -4)} # km\n",
    "\n",
    "arcs = {'e1': ['n1', 'n2'],\n",
    "        'e2': ['n1', 'n4'],\n",
    "        'e3': ['n2', 'n3'],\n",
    "        'e4': ['n2', 'n5'],\n",
    "        'e5': ['n3', 'n6'],\n",
    "        'e6': ['n4', 'n5'],\n",
    "        'e7': ['n5', 'n6']}\n",
    "\n",
    "# Fragility curves -- From HAZUS-EQ model (roads are regarded as disconnected when being extensively or completely damaged)\n",
    "\n",
    "frag = {'major': {'med': 60.0, 'std': 0.7},\n",
    "        'urban' : {'med': 24.0, 'std': 0.7},\n",
    "        'bridge': {'med': 1.1, 'std': 3.9}}\n",
    "\n",
    "arcs_type = {'e1': 'major',\n",
    "             'e2': 'bridge',\n",
    "             'e3': 'urban',\n",
    "             'e4': 'bridge',\n",
    "             'e5': 'major',\n",
    "             'e6': 'urban',\n",
    "             'e7': 'major'}\n",
    "\n",
    "arcs_avg_kmh = {'e1': 50,\n",
    "                'e2': 50,\n",
    "                'e3': 30,\n",
    "                'e4': 50,\n",
    "                'e5': 50,\n",
    "                'e6': 30,\n",
    "                'e7': 50}\n",
    "\n",
    "var_ODs = {'od1': ('n1', 'n4'),\n",
    "           'od2': ('n1', 'n5'),\n",
    "           'od3': ('n1', 'n6')}\n",
    "\n",
    "nODs = len(var_ODs)\n",
    "\n",
    "# Arcs' states index compatible with variable B index, and C\n",
    "arc_surv = 1 - 1\n",
    "arc_fail = 2 - 1\n",
    "arc_either = 3 - 1\n",
    "\n",
    "arc_lens_km = get_arcs_length(arcs, node_coords)\n",
    "\n",
    "# Distance to epicentre (epicentre is assumed to have been observed.)\n",
    "arcs_cloc_km = {}\n",
    "for k, v in arcs.items():\n",
    "    cloc = 0.5 * (np.array( node_coords[v[0]] ) + np.array( node_coords[v[1]] ))\n",
    "    arcs_cloc_km[k] = cloc\n",
    "\n",
    "epi_loc_km = (20, -3)\n",
    "arcs_epi_dist_km = {}\n",
    "for k, v in arcs_cloc_km.items():\n",
    "    diff = np.array(v) - np.array(epi_loc_km)\n",
    "    arcs_epi_dist_km[k] = np.sqrt(np.sum(diff**2))\n",
    "print(arcs_epi_dist_km)\n",
    "\n",
    "#arcTimes_h = arcLens_km ./ arcs_Vavg_kmh\n",
    "arc_times_h = {k: v/arcs_avg_kmh[k] for k, v in arc_lens_km.items()}\n",
    "\n",
    "# create a graph\n",
    "G = nx.Graph()\n",
    "for k, x in arcs.items():\n",
    "    G.add_edge(x[0], x[1], time=arc_times_h[k], label=k)\n",
    "\n",
    "for k, v in node_coords.items():\n",
    "    G.add_node(k, pos=v)\n",
    "\n",
    "path_time = get_all_paths_and_times(var_ODs.values(), G, key='time')\n",
    "print( path_time )\n",
    "\n",
    "# plot graph\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "nx.draw(G, pos, with_labels=True, ax=ax)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, ax=ax)\n",
    "fig.savefig( os.path.join(HOME, 'graph_toy.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8f4a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('n1', 'n4'): [(['e1', 'e3', 'e5', 'e7', 'e6'], 0.2733333333333333), (['e1', 'e4', 'e6'], 0.16666666666666669), (['e2'], 0.06)], ('n1', 'n5'): [(['e1', 'e3', 'e5', 'e7'], 0.20666666666666667), (['e1', 'e4'], 0.1), (['e2', 'e6'], 0.12666666666666665)], ('n1', 'n6'): [(['e1', 'e3', 'e5'], 0.16666666666666666), (['e1', 'e4', 'e7'], 0.14), (['e2', 'e6', 'e4', 'e3', 'e5'], 0.3133333333333333), (['e2', 'e6', 'e7'], 0.16666666666666666)]}\n"
     ]
    }
   ],
   "source": [
    "print( path_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad1533",
   "metadata": {},
   "source": [
    "# Add and sample hazard nodes.\n",
    "\n",
    "We assume magnitude and epicentre are observed, and sample intensity measures (IMs) experienced by each component event. Note that such samples can be obtained by any approaches (e.g. ground motion prediction equations (GMPEs) or detailed simulation tools like Global Earthquake Model (GEM)). <br>\n",
    "Here, we employ a GMPE proposed by Campbell (1997) for peak ground acceleration (PGA) and HAZUS EQ model for permanent ground displacement (PGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "963ca6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[ log(A_H) ] for each arc (component):\n",
      "{'e1': 0.2529664900800276, 'e2': 0.26886113914642845, 'e3': 0.2540890253419107, 'e4': 0.2714972127053331, 'e5': 0.2714972127053331, 'e6': 0.28968581274095156, 'e7': 0.2912683553162252}\n"
     ]
    }
   ],
   "source": [
    "eq_m = 7 # observed\n",
    "\n",
    "arcs_lpga_mean = {}\n",
    "for k, v in arcs_epi_dist_km.items():\n",
    "    lpga_mean = -3.512 + 0.904 * eq_m - 1.312 * np.log( np.sqrt( v**2 + (0.149 * np.exp(0.647*eq_m))**2 ) ) # Campbell (1997)\n",
    "    arcs_lpga_mean[k] = lpga_mean\n",
    "print( 'E[ log(A_H) ] for each arc (component):' )\n",
    "print( {k: np.exp(v) for k,v in arcs_lpga_mean.items()} )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe16de",
   "metadata": {},
   "source": [
    "We get the samples of PGA. Note that this is not an entirely correct application of Campbell (1997). Procedure is simplified to just to quickly get samples of IM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc645685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.079 0.152 0.131 0.201 0.227 0.217 0.377]\n",
      " [0.306 0.57  0.676 0.102 0.343 0.364 0.36 ]\n",
      " [0.103 0.231 0.365 0.136 0.424 0.322 0.198]\n",
      " [0.145 0.49  0.373 0.131 0.07  0.114 0.247]\n",
      " [0.257 0.254 0.127 0.198 0.33  0.194 0.312]\n",
      " [0.298 0.371 0.312 0.073 1.403 0.712 0.324]\n",
      " [0.425 0.468 0.644 0.256 0.172 0.204 0.187]\n",
      " [0.17  0.148 0.229 0.441 0.114 0.9   0.319]\n",
      " [0.135 0.438 0.157 0.212 0.191 0.213 0.206]\n",
      " [0.182 0.61  0.168 0.453 0.169 0.15  0.13 ]]\n"
     ]
    }
   ],
   "source": [
    "no_samp = 10\n",
    "no_arc = len(arcs)\n",
    "\n",
    "cpms = {}\n",
    "varbs = {}\n",
    "\n",
    "C_pga = np.empty(shape=(no_samp, no_arc))\n",
    "for i in range(no_arc):\n",
    "    lpga_mean = arcs_lpga_mean['e'+str(i+1)]\n",
    "    lpga_samps = np.random.normal( loc = lpga_mean, scale = 0.55, size = (no_samp,) )\n",
    "    pga_samps = np.exp( lpga_samps )\n",
    "    C_pga[:,i] = pga_samps\n",
    "print(C_pga)\n",
    "\n",
    "\n",
    "# TODO: Below does not work. CPM needs to be able to be defined over continuous or sampled variables.\n",
    "#varbs['pga'] = variable.Variable(name='pga', B = [], values = [])\n",
    "#p = np.empty(shape = (no_samp, 1))\n",
    "#q = np.empty(shape = (no_samp, 1))\n",
    "#cpms['pga'] = cpm.Cpm( variables = [varbs['pga']], no_child = no_arc, C = C_pga, p = p, q = q )\n",
    "#print(varbs['pga'])\n",
    "#print(cpms['pga'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd4074",
   "metadata": {},
   "source": [
    "Sample PGD. \n",
    "\n",
    "For PGD, which is the IM for paved roads, the causal mechanism is assumed as lateral spreading due to liquefaction (ref: HAZUS EQ model). <br>\n",
    "Uncerty in PGD arises from PGA. For the moment, uncertainty in susceptibility category, and susceptibility category is assumed to be a single category (ref: Table 4-12 in HAZUS EQ model is ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a12e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 7.609e-01 2.927e-01 7.397e+00]\n",
      " [4.241e+00 1.928e+01 3.506e+01 0.000e+00 5.898e+00 6.815e+00 6.651e+00]\n",
      " [0.000e+00 9.127e-01 6.859e+00 0.000e+00 9.578e+00 4.976e+00 0.000e+00]\n",
      " [0.000e+00 1.396e+01 7.232e+00 0.000e+00 0.000e+00 0.000e+00 1.663e+00]\n",
      " [2.081e+00 1.971e+00 0.000e+00 0.000e+00 5.323e+00 0.000e+00 4.529e+00]\n",
      " [3.887e+00 7.122e+00 4.539e+00 0.000e+00 2.234e+02 4.442e+01 5.051e+00]\n",
      " [9.623e+00 1.248e+01 2.695e+01 2.037e+00 0.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 8.543e-01 1.068e+01 0.000e+00 9.328e+01 4.824e+00]\n",
      " [0.000e+00 1.054e+01 0.000e+00 9.368e-02 0.000e+00 1.387e-01 0.000e+00]\n",
      " [0.000e+00 2.197e+01 0.000e+00 1.152e+01 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "pga_c = 0.21 # (g) for Low\n",
    "\n",
    "k_del = 0.0086 * eq_m**3 - 0.0914*eq_m**2 + 0.4698*eq_m - 0.9835\n",
    "\n",
    "C_pgd = np.empty(shape=(no_samp, no_arc))\n",
    "for i in range(no_arc):\n",
    "    for j in range(no_samp):\n",
    "        pga = C_pga[j,i]\n",
    "\n",
    "        pga_rat = pga / pga_c\n",
    "        if pga_rat < 1:\n",
    "            pgd = 0\n",
    "        elif pga_rat < 2:\n",
    "            pgd = 12*pga_rat - 12 # inch\n",
    "        elif pga_rat < 3:\n",
    "            pgd = 18*pga_rat - 24\n",
    "        else:\n",
    "            pgd = 70*pga_rat - 180\n",
    "        \n",
    "        C_pgd[j,i] = k_del * pgd\n",
    "        \n",
    "print(C_pgd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ff0ba",
   "metadata": {},
   "source": [
    "Now we assume that we observed PGA at e2 and e5 by 0.2g and 0.3g respectively. We also assume that there is 10% of observation error. <br>\n",
    "This updates sample weights by $f(oa_2 | a_2) \\cdot f(oa_5 | a_5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ba58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.486e-002]\n",
      " [5.045e-122]\n",
      " [3.933e-013]\n",
      " [6.288e-023]\n",
      " [6.180e-004]\n",
      " [4.889e-046]\n",
      " [1.224e-107]\n",
      " [9.175e-086]\n",
      " [4.081e-001]\n",
      " [2.671e-004]]\n"
     ]
    }
   ],
   "source": [
    "q = np.ones(shape=(no_samp,1)) # sample weight vector\n",
    "\n",
    "for j in range(no_samp):\n",
    "    q_j = norm.pdf( 0.2, C_pga[j, 2], scale = 0.2*0.1 ) * norm.pdf( 0.3, C_pga[j, 5], scale = 0.3*0.1 )\n",
    "    q[j] = q_j\n",
    "    \n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713cc67",
   "metadata": {},
   "source": [
    "# Now component and system events.\n",
    "\n",
    "First, we compute P(X_n=fail | sample_j)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e35ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.306]\n",
      " [0.433]\n",
      " [0.344]\n",
      " [0.418]\n",
      " [0.354]\n",
      " [0.39 ]\n",
      " [0.413]\n",
      " [0.303]\n",
      " [0.407]\n",
      " [0.44 ]]\n"
     ]
    }
   ],
   "source": [
    "arcs_pf = {}\n",
    "\n",
    "for i in range(no_arc):\n",
    "    k = 'e' + str(i+1)\n",
    "    pf = np.zeros(shape=(no_samp,1))\n",
    "    \n",
    "    for j in range(no_samp):\n",
    "        _type = arcs_type[k]\n",
    "        if _type == 'bridge':\n",
    "            prob = lognorm.cdf(C_pga[j,i], frag[_type]['std'], scale=frag[_type]['med'])\n",
    "        else:\n",
    "            prob = lognorm.cdf(C_pgd[j,i], frag[_type]['std'], scale=frag[_type]['med'])\n",
    "        pf[j] = prob\n",
    "        \n",
    "    arcs_pf[k] = pf\n",
    "\n",
    "    \n",
    "print(arcs_pf['e2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c711c",
   "metadata": {},
   "source": [
    "Quantify system (functionality) events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f4e276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n1', 'n4')\n"
     ]
    }
   ],
   "source": [
    "print(var_ODs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ca2e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[(['e1', 'e3', 'e5', 'e7', 'e6'], 0.2733333333333333), (['e1', 'e4', 'e6'], 0.16666666666666669), (['e2'], 0.06)]\n",
      "[inf, 0.06, 0.16666666666666669, 0.2733333333333333]\n"
     ]
    }
   ],
   "source": [
    "print(len(path_time[var_ODs[k]]))\n",
    "print(path_time[var_ODs[k]])\n",
    "\n",
    "times = [x[1] for x in path_time[var_ODs[k]]]\n",
    "times.sort()\n",
    "times.insert(0, np.inf)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # System event index\n",
    "k = 'od' + str(i+1)\n",
    "no_path = len(path_time[var_ODs[k]])\n",
    "variables[k] = variable.Variable(name=k, B=np.eye(no_path), values=['Fail', 'Surv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e97d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf, 0.2733333333333333, 0.16666666666666669, 0.06]\n",
      "[([], inf, 0), (['e2'], 0.06, 3), (['e1', 'e4', 'e6'], 0.16666666666666669, 2), (['e1', 'e3', 'e5', 'e7', 'e6'], 0.2733333333333333, 1)]\n"
     ]
    }
   ],
   "source": [
    "variables = {}\n",
    "\n",
    "i = 0 # System event index\n",
    "k = 'od' + str(i+1)\n",
    "\n",
    "times = [x[1] for x in path_time[var_ODs[k]]]\n",
    "times.sort(reverse=True)\n",
    "times.insert(0, np.inf)\n",
    "no_path = len(times)\n",
    "print(times)\n",
    "\n",
    "variables[k] = variable.Variable(name=k, B=np.eye(no_path), values=times)\n",
    "path_time_idx = get_path_time_idx( path_time[var_ODs[k]], variables[k])\n",
    "\n",
    "print(path_time_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1de8368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncomp_max_states = 2\\n\\npaths = [x[0] for x in path_time_idx]\\npaths.remove([])\\n\\ninfo = {'path': [[2], [3, 1]],\\n        'time': np.array([0.0901, 0.2401]),\\n        'arcs': [i for i in range(1,len(arcs))],\\n        'max_state': comp_max_states\\n       }\\n\\nbranches = branch.run_bnb(sys_fn=bnb_fns.bnb_sys,\\n                       next_comp_fn=bnb_fns.bnb_next_comp,\\n                       next_state_fn=bnb_fns.bnb_next_state,\\n                       info=info,\\n                       comp_max_states=comp_max_states)\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "comp_max_states = 2\n",
    "\n",
    "paths = [x[0] for x in path_time_idx]\n",
    "paths.remove([])\n",
    "\n",
    "info = {'path': [[2], [3, 1]],\n",
    "        'time': np.array([0.0901, 0.2401]),\n",
    "        'arcs': [i for i in range(1,len(arcs))],\n",
    "        'max_state': comp_max_states\n",
    "       }\n",
    "\n",
    "branches = branch.run_bnb(sys_fn=bnb_fns.bnb_sys,\n",
    "                       next_comp_fn=bnb_fns.bnb_next_comp,\n",
    "                       next_state_fn=bnb_fns.bnb_next_state,\n",
    "                       info=info,\n",
    "                       comp_max_states=comp_max_states)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c326e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "branch_and_bound() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13144\\3133632288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0marc_condn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranch_and_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_time_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marc_condn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: branch_and_bound() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "lower = {x: 0 for x in arcs}  # Fail\n",
    "upper = {x: 1 for x in arcs}  # surv\n",
    "arc_condn = 1\n",
    "\n",
    "\n",
    "#######TODO: branch_and_bound no longer works#################\n",
    "sb = branch_and_bound(path_time_idx, lower, upper, arc_condn)\n",
    "############################################################\n",
    "\n",
    "B = np.array([[1, 0], [0, 1], [1, 1]])\n",
    "for i in range(1, 8):\n",
    "    variables[f'e{i}'] = variable.Variable(name=f'e{i}', B=B, values=['Fail', 'Surv'])\n",
    "Cmat = get_cmat_from_branches(sb, variables)\n",
    "print(Cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112d56c",
   "metadata": {},
   "source": [
    "Calculate a probability vector correponding to Cmat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87798d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_c = len(Cmat)\n",
    "p = np.ones(shape = (no_c, no_samp))\n",
    "\n",
    "for i in range(no_arc):\n",
    "    k = f'e{i+1}'\n",
    "    pf_i = arcs_pf[k]\n",
    "    \n",
    "    for j in range(no_samp):\n",
    "\n",
    "        for k in range(no_c):\n",
    "            C_ik = Cmat[k,i+1]\n",
    "            if C_ik == 0:\n",
    "                prob_ijk = pf_i[j]\n",
    "            elif C_ik == 1:\n",
    "                prob_ijk = 1 - pf_i[j]\n",
    "            else:\n",
    "                prob_ijk = 1\n",
    "\n",
    "            p[k,j] *= prob_ijk\n",
    "    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6648354",
   "metadata": {},
   "source": [
    "System probability of OD1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sys_probs( Cmat, p ):\n",
    "\n",
    "    denom = np.sum( p ) # denominator of importance sampling\n",
    "    numers = np.sum(p, axis=1)\n",
    "\n",
    "    no_sys_st = max([x[0] for x in Cmat])\n",
    "    sys_probs = np.empty(shape=(no_sys_st+1,))\n",
    "    for i in range(no_sys_st+1):\n",
    "        pos = np.argwhere(Cmat[:,0]==i)\n",
    "        prob = np.sum(numers[pos]) / denom\n",
    "        sys_probs[i] = prob\n",
    "        \n",
    "    return sys_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_probs = cal_sys_probs( Cmat, p )\n",
    "print(sys_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ce72f",
   "metadata": {},
   "source": [
    "# Updating system events by observations on component events.\n",
    "\n",
    "Suppose e1 and e3 are observed to be failed. There is 90% of probability that an observation is correct (i.e. observation error of 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "ox = {'e1': 0, 'e6': 0}\n",
    "ox_corr = 0.9\n",
    "c_st = 2 # composite state (representing either of both states)\n",
    "\n",
    "p_ox = copy.deepcopy(p)\n",
    "for k, v in ox.items():\n",
    "    arc_ind = int(k[1])\n",
    "    \n",
    "    for i in range(no_c):\n",
    "        if Cmat[i,arc_ind] == v:\n",
    "            p_ox[i] *= ox_corr\n",
    "        elif Cmat[i,arc_ind] != c_st:\n",
    "            p_ox[i] *= (1-ox_corr)\n",
    "\n",
    "            \n",
    "sys_probs_ox = cal_sys_probs( Cmat, p_ox )\n",
    "print(sys_probs_ox)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977514ae",
   "metadata": {},
   "source": [
    "# Updating component events by observations on system events.\n",
    "\n",
    "Suppose od1 is observed to be delayed. We have probabilities of [0.2, 0.4, 0.4, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "of = {'od1': [0.2, 0.4, 0.4, 0]}\n",
    "\n",
    "p_of = copy.deepcopy(p)\n",
    "for k, v in of.items():\n",
    "    arc_ind = int( k[2] )\n",
    "    \n",
    "    for i in range( no_c ):\n",
    "        p_of[i] *= v[Cmat[i,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8901bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_comp_probs( Cmat, p, comp_ind ):\n",
    "\n",
    "    numers = np.sum(p, axis=1)\n",
    "\n",
    "    no_st = 2 # fail or survival (multi-state is not considered at the moment)\n",
    "    probs = np.empty(shape=(no_st,))\n",
    "    for i in range(no_st):\n",
    "        pos = np.argwhere(Cmat[:,comp_ind+1]==i)\n",
    "        prob = np.sum(numers[pos]) \n",
    "        probs[i] = prob\n",
    "    \n",
    "    probs = probs / np.sum(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_of_x1 = cal_comp_probs( Cmat, p_of, 1 )\n",
    "print(probs_of_x1)\n",
    "\n",
    "probs_of_x2 = cal_comp_probs( Cmat, p_of, 2 )\n",
    "print(probs_of_x2)\n",
    "\n",
    "probs_of_x3 = cal_comp_probs( Cmat, p_of, 3 )\n",
    "print(probs_of_x3)\n",
    "\n",
    "probs_of_x4 = cal_comp_probs( Cmat, p_of, 4 )\n",
    "print(probs_of_x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f4e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4cd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a77cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
